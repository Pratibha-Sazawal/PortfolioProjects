{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91385741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import smtplib    # Used to send emails to ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f20d18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            WOW Skin Science Coconut Milk Hair Mask with Coconut Milk, 200 ml\n",
      "           \n",
      "\n",
      "             732 ratings\n",
      "            \n",
      "\n",
      "                        ₹349.00\n",
      "                       \n"
     ]
    }
   ],
   "source": [
    "# We have to tell BeautifulSoup and requests where we are getting this data from\n",
    "\n",
    "# Connect to website\n",
    "\n",
    "URL = 'https://www.amazon.in/gp/product/B07YYCKR11/ref=ox_sc_saved_title_4?smid=A2WK4OB3ROODF0&psc=1'\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "# User-Agent part is specific to our computer - get from this link - https://httpbin.org/get\n",
    "\n",
    "page = requests.get(URL, headers = headers) \n",
    "# This is where we'll start getting the data\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")   # Pulling in all the html\n",
    "# print(soup1)\n",
    "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")  # Pulling in the content, Prettify jusy makes things look better\n",
    "# print(soup2)\n",
    "\n",
    "# soup2 was all the html that we can get\n",
    "# Now we'll specify what things we actually want - eg. product title\n",
    "# We can get this id by clicking on inspect element of the particular webpage\n",
    "\n",
    "title = soup2.find(id = \"productTitle\").get_text()\n",
    "print(title)\n",
    "reviews = soup2.find(id = \"acrCustomerReviewText\").get_text()\n",
    "print(reviews)\n",
    "price = soup2.find(\"span\", attrs={'class':'a-offscreen'}).get_text()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8657f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\n",
      "WOW Skin Science Coconut Milk Hair Mask with Coconut Milk, 200 ml\n",
      "349.00\n"
     ]
    }
   ],
   "source": [
    "# Need to clean this up - eg. too much blank space\n",
    "\n",
    "reviews = reviews.strip()[-9::-1]   #removing blank space and the word ratings\n",
    "reviews = reviews[-1::-1]\n",
    "\n",
    "title = title.strip()\n",
    "\n",
    "price = price.strip()[1:]\n",
    "\n",
    "print(reviews)\n",
    "print(title)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "147a4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18\n"
     ]
    }
   ],
   "source": [
    "# Timestamp for when we collected this data\n",
    "\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03e7039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a csv file to insert this data into\n",
    "\n",
    "import csv\n",
    " \n",
    "header = [\"Title\", \"Price\", \"Reviews\", \"Date\"]\n",
    "\n",
    "# Right now our data is in string format - we want to make it a list\n",
    "\n",
    "data = [title, price, reviews, today]\n",
    "type(data)  # It's a list now\n",
    "\n",
    "with open(\"AmazonWebScraperDataset.csv\", \"w\", newline =\"\", encoding = 'UTF8') as f:\n",
    "# newline specifies how to end a line in the csv - by default it leaves a blank line (space) - \"\" will not leave that blank line\n",
    "# UTF8 - common encoding, 8 means 8-bit values are used in the encoding\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)   # Initial insertion of data into the csv\n",
    "    writer.writerow(data)\n",
    "    \n",
    "# We are creating the csv and then inserting the header and then the data\n",
    "\n",
    "# This overwrites data everytime we run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eacbeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price  Reviews  \\\n",
      "0  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "1  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "2  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "3  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "\n",
      "         Date  \n",
      "0  2023-01-18  \n",
      "1  2023-01-18  \n",
      "2  2023-01-18  \n",
      "3  2023-01-18  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"AmazonWebScraperDataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f23d7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to append more data to this csv\n",
    "\n",
    "with open(\"AmazonWebScraperDataset.csv\", \"a+\", newline =\"\", encoding = 'UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ec93e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to automate this whole process\n",
    "\n",
    "def check_price():\n",
    "    URL = 'https://www.amazon.in/gp/product/B07YYCKR11/ref=ox_sc_saved_title_4?smid=A2WK4OB3ROODF0&psc=1'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    page = requests.get(URL, headers = headers) \n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")   \n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")  \n",
    "    title = soup2.find(id = \"productTitle\").get_text()\n",
    "    reviews = soup2.find(id = \"acrCustomerReviewText\").get_text()\n",
    "    price = soup2.find(\"span\", attrs={'class':'a-offscreen'}).get_text()\n",
    "\n",
    "    reviews = reviews.strip()[-9::-1]   \n",
    "    reviews = reviews[-1::-1]\n",
    "    title = title.strip()\n",
    "    price = price.strip()[1:]\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    header = [\"Title\", \"Price\", \"Reviews\", \"Date\"]\n",
    "    data = [title, price, reviews, today]\n",
    "    \n",
    "    with open(\"AmazonWebScraperDataset.csv\", \"a+\", newline =\"\", encoding = 'UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8df3ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)   # Every 24 hours - 86400 sec, it runs through this entire process\n",
    "    \n",
    "# We are checking the review count every 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbb0feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price  Reviews  \\\n",
      "0  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "1  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "2  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "3  WOW Skin Science Coconut Milk Hair Mask with C...  349.0      732   \n",
      "\n",
      "         Date  \n",
      "0  2023-01-18  \n",
      "1  2023-01-18  \n",
      "2  2023-01-18  \n",
      "3  2023-01-18  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmazonWebScraperDataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fc59c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to get an email everytime the price of the product drops below a certain value\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('pratibhasazawal@gmail.com','dmumt2912')\n",
    "    \n",
    "    subject = \"The mask you want is below ₹300! Now is your chance to buy!\"\n",
    "    body = \"Pratibha, This is the moment we have been waiting for. Now is your chance to pick up the mask of your dreams. Don't mess it up! Link here: https://www.amazon.in/gp/product/B07YYCKR11/ref=ox_sc_saved_title_4?smid=A2WK4OB3ROODF0&psc=1\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    server.sendmail(\n",
    "        'pratibhasazawal@gmail.com',\n",
    "        msg\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3cd131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price2():\n",
    "    URL = 'https://www.amazon.in/gp/product/B07YYCKR11/ref=ox_sc_saved_title_4?smid=A2WK4OB3ROODF0&psc=1'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    page = requests.get(URL, headers = headers) \n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")   \n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")  \n",
    "    title = soup2.find(id = \"productTitle\").get_text()\n",
    "    reviews = soup2.find(id = \"acrCustomerReviewText\").get_text()\n",
    "    price = soup2.find(\"span\", attrs={'class':'a-offscreen'}).get_text()\n",
    "\n",
    "    reviews = reviews.strip()[-9::-1]   \n",
    "    reviews = reviews[-1::-1]\n",
    "    title = title.strip()\n",
    "    price = price.strip()[1:]\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    header = [\"Title\", \"Price\", \"Reviews\", \"Date\"]\n",
    "    data = [title, price, reviews, today]\n",
    "    \n",
    "    with open(\"AmazonWebScraperDataset.csv\", \"a+\", newline =\"\", encoding = 'UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "        \n",
    "    if (price <= 300):\n",
    "        send_mail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca042f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
